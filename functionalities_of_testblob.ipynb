{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4YwCILkxA5ulIrpcNfbrG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeerbaniShashi/NLP_all/blob/main/functionalities_of_testblob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KS8KQy7UpNx",
        "outputId": "89776b50-3b15-4c97-ca96-e776462c1310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "###install TextBlob\n",
        "!pip install nltk\n",
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tQZYKw-X5-Y",
        "outputId": "9658459c-cd41-40a0-b46b-7506a2ac37ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kl4Qr-uX6Lz",
        "outputId": "a3f83a93-86af-419e-eeca-0a84703dd03f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b760f6e6",
        "outputId": "cd99f03b-4220-409a-f125-0a0c532566ad"
      },
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQDDGKwUtdbB",
        "outputId": "ce2f1c7c-240c-489a-a675-c72ed3380d3b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8446C4Oth1h",
        "outputId": "065de942-839d-4539-fca5-085c4348027b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora lite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGa3aJ1AtlIk",
        "outputId": "dafda47c-3ee9-4ed5-c26a-e04d63cb2bea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "from textblob import TextBlob\n",
        "from textblob.taggers import PatternTagger\n",
        "from textblob.sentiments import PatternAnalyzer\n",
        "\n",
        "blob = TextBlob(\"Hey John, How are You? Nice to meet you.\", pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "# Install the language detection library\n",
        "!pip install textblob-fr\n",
        "# TextBlob uses `detect` for language detection, not `detect_language`\n",
        "#print(\"Detected language is:\", blob.detect_language())\n",
        "#print(\"Input text in Spanish:\", blob.translate(to = 'es'))\n",
        "#print(\"Input text in Bengali:\", blob.translate(to = 'bn'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE7y_38mX6TH",
        "outputId": "4c6c8d37-2276-44b1-8817-a2a951ba8d07"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob-fr in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: textblob>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from textblob-fr) (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob>=0.8.0->textblob-fr) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.8.0->textblob-fr) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.8.0->textblob-fr) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.8.0->textblob-fr) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob>=0.8.0->textblob-fr) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spelling correction\n",
        "from textblob import TextBlob\n",
        "text = \"\"\"ABCD Corp alays values ttheir employees!!!\"\"\""
      ],
      "metadata": {
        "id": "HTYSJRhFnPEd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlUVPO3qnPOo",
        "outputId": "377aa27b-4342-4ac1-d8e8-da49b5be0319"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABCD Corp alays values ttheir employees!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(text)"
      ],
      "metadata": {
        "id": "bx4KnJPSnPTk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_hBXLLpnPU4",
        "outputId": "878e355a-2ac9-48de-b5e9-f0dc1b5f6478"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"ABCD Corp alays values ttheir employees!!!\")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0hLgn36nsHr",
        "outputId": "bdc42e0d-65e5-4874-d4cb-8cc5ee6bf0cf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"ABCD For always values their employees!!!\")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob('hass').correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kDQaRcynsJT",
        "outputId": "d6ed777a-f26b-4c94-9ef1-6a077418ff03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"has\")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Sometimes it fails as well\n",
        "TextBlob('ur').correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQgdpaConsNN",
        "outputId": "4e38f480-94e4-4971-c5e7-fa92d742bcdb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"or\")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Count\n",
        "text = \"Sentiment Analysis is a process by which we can find the sentiment of a text. Sentiment can be Positive, Negative, or Neutral.\""
      ],
      "metadata": {
        "id": "odQ1-yhJnsOy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(text)"
      ],
      "metadata": {
        "id": "6uztjEisoT3Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob.word_counts[\"analysis\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHTrPvu3oT4Y",
        "outputId": "ddca308d-f7bb-4668-f1aa-03e5814a775c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.word_counts[\"Sentiment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsnYXI5-oT95",
        "outputId": "655ef1aa-95e8-45e0-9950-afd34b0ca128"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.word_counts[\"sentiment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "844aeQG4oT-x",
        "outputId": "91a33509-b3d7-4d36-ee2e-5d78c7185370"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.word_counts[\"Analysis\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq8ZP7IqoepO",
        "outputId": "c7e9e1bb-1bd9-4ddb-848a-3063c4c0c9e9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###POS tagging\n",
        "from textblob import TextBlob\n",
        "text = TextBlob(\"My name is Adam. I like to read about NLP. I work at ABCD Corp.\")\n",
        "print(text.tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJbtG5nxov8t",
        "outputId": "68150f8d-2fde-4ec8-c8af-6d41c49a71ed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Adam', 'NNP'), ('I', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('read', 'VB'), ('about', 'IN'), ('NLP', 'NNP'), ('I', 'PRP'), ('work', 'VBP'), ('at', 'IN'), ('ABCD', 'NNP'), ('Corp', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tuple = []\n",
        "for i in text.tags:\n",
        "  print(i)\n",
        "  if 'VBP' not in i[1]:\n",
        "    new_tuple.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZl2sO8owGe",
        "outputId": "ff379650-e131-40ba-bfec-ffc508a7404f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('My', 'PRP$')\n",
            "('name', 'NN')\n",
            "('is', 'VBZ')\n",
            "('Adam', 'NNP')\n",
            "('I', 'PRP')\n",
            "('like', 'VBP')\n",
            "('to', 'TO')\n",
            "('read', 'VB')\n",
            "('about', 'IN')\n",
            "('NLP', 'NNP')\n",
            "('I', 'PRP')\n",
            "('work', 'VBP')\n",
            "('at', 'IN')\n",
            "('ABCD', 'NNP')\n",
            "('Corp', 'NNP')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tuple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fjaKf3GowHs",
        "outputId": "c60d32d3-7cac-4bf0-e62e-17c6ed9e4980"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('My', 'PRP$'),\n",
              " ('name', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('Adam', 'NNP'),\n",
              " ('I', 'PRP'),\n",
              " ('to', 'TO'),\n",
              " ('read', 'VB'),\n",
              " ('about', 'IN'),\n",
              " ('NLP', 'NNP'),\n",
              " ('I', 'PRP'),\n",
              " ('at', 'IN'),\n",
              " ('ABCD', 'NNP'),\n",
              " ('Corp', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = ''\n",
        "for i in new_tuple:\n",
        "  value = value + \" \" + ''.join(i[0])"
      ],
      "metadata": {
        "id": "gMhejen6owOe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5Cu7p0EXowPd",
        "outputId": "e9c9e8d0-79e3-4764-c626-621c307a658a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' My name is Adam I to read about NLP I at ABCD Corp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "text=\"\"\"\n",
        "R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts. It is free and runs on a variety of platforms, including Windows, Unix, and macOS. It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ieN3p-mGowVh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob_object = TextBlob(text)"
      ],
      "metadata": {
        "id": "YBHlpUCyppJt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenization of the sample corpus\n",
        "corpus_words = blob_object.words"
      ],
      "metadata": {
        "id": "7BTruiDNppLB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcsNnHNFppQz",
        "outputId": "f8db8d81-d1a5-4fa8-b425-3df5e37786bd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['R', 'is', 'a', 'comprehensive', 'statistical', 'and', 'graphical', 'programming', 'language', 'which', 'is', 'fast', 'gaining', 'popularity', 'among', 'data', 'analysts', 'It', 'is', 'free', 'and', 'runs', 'on', 'a', 'variety', 'of', 'platforms', 'including', 'Windows', 'Unix', 'and', 'macOS', 'It', 'provides', 'an', 'unparalleled', 'platform', 'for', 'programming', 'new', 'statistical', 'methods', 'in', 'an', 'easy', 'and', 'straightforward', 'manner'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(corpus_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0z-m59cppR-",
        "outputId": "dd361167-6beb-4797-cfe6-fa859133e564"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sentences = blob_object.sentences"
      ],
      "metadata": {
        "id": "Hzw56eKEppX8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UShq2sBhppZH",
        "outputId": "5b6a3dca-0767-45c8-fdcb-95c66af0cf30"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence(\"\n",
              " R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts.\"),\n",
              " Sentence(\"It is free and runs on a variety of platforms, including Windows, Unix, and macOS.\"),\n",
              " Sentence(\"It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(corpus_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhXu2ILeppe6",
        "outputId": "6eedf03a-a9a8-4660-f278-388176d8b7bf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pluralization of words using TextBlob\n",
        "from textblob import Word\n",
        "w = Word(\"Platform\")\n",
        "w.pluralize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lZR3A-_Kppgb",
        "outputId": "4b762c14-9d82-4f65-88fd-fad4b9f31113"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Platforms'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "w = Word(\"Platforms\")\n",
        "w.pluralize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MltBKGJYppmY",
        "outputId": "ec133218-94c1-4659-c590-9bf47efd7425"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Platformss'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA, etc.\")\n",
        "for word, pos in blob.tags:\n",
        "  if pos == 'NN':\n",
        "    print(word.pluralize())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqNHTZn9ppnu",
        "outputId": "a354dded-cdfa-4874-fc96-97765daebf11"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "platforms\n",
            "sciences\n",
            "communities\n",
            "etcs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization using TextBlob\n",
        "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA, etc.\")\n",
        "words = blob.words\n",
        "for word in words:\n",
        "  print(\"ORIGINAL:\", word, \"| LEMMA:\", word.lemmatize(), \"| STEM:\", word.stem())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0L9Afb1pp9X",
        "outputId": "0ba76a78-99cf-4665-add2-07da541883b5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL: Great | LEMMA: Great | STEM: great\n",
            "ORIGINAL: Learning | LEMMA: Learning | STEM: learn\n",
            "ORIGINAL: is | LEMMA: is | STEM: is\n",
            "ORIGINAL: a | LEMMA: a | STEM: a\n",
            "ORIGINAL: great | LEMMA: great | STEM: great\n",
            "ORIGINAL: platform | LEMMA: platform | STEM: platform\n",
            "ORIGINAL: to | LEMMA: to | STEM: to\n",
            "ORIGINAL: learn | LEMMA: learn | STEM: learn\n",
            "ORIGINAL: data | LEMMA: data | STEM: data\n",
            "ORIGINAL: science | LEMMA: science | STEM: scienc\n",
            "ORIGINAL: It | LEMMA: It | STEM: it\n",
            "ORIGINAL: helps | LEMMA: help | STEM: help\n",
            "ORIGINAL: community | LEMMA: community | STEM: commun\n",
            "ORIGINAL: through | LEMMA: through | STEM: through\n",
            "ORIGINAL: blogs | LEMMA: blog | STEM: blog\n",
            "ORIGINAL: Youtube | LEMMA: Youtube | STEM: youtub\n",
            "ORIGINAL: GLA | LEMMA: GLA | STEM: gla\n",
            "ORIGINAL: etc | LEMMA: etc | STEM: etc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Word('learning')\n",
        "w.lemmatize('n') # here n represents noun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T7iDow8FsKYm",
        "outputId": "5eca0b74-d4f0-44e4-9580-d74365db3272"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Word('learning')\n",
        "w.lemmatize('v') # here v represents verb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "soO26oBtsKp0",
        "outputId": "06a1026e-b68b-400d-89b9-0490fe5de6ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'learn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Word('peoples')\n",
        "w.lemmatize('n') # here n represents noun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lV_EX2zmsKv2",
        "outputId": "ea00b3c0-2984-4397-c2e1-1c14e6136d1e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'people'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###n-grams in TextBlob\n",
        "blob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si89uW1KsKw_",
        "outputId": "fab7f6f0-da9c-4ac3-a9ef-6fe827da8fd6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"Great Learning is a great platform to learn data science. \n",
              " It helps community through blogs, Youtube, GLA, etc.\")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.ngrams(n = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9no3JvYsK3c",
        "outputId": "e2c857f6-dc76-4a79-bc6f-3a7265bcd78c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great']),\n",
              " WordList(['Learning']),\n",
              " WordList(['is']),\n",
              " WordList(['a']),\n",
              " WordList(['great']),\n",
              " WordList(['platform']),\n",
              " WordList(['to']),\n",
              " WordList(['learn']),\n",
              " WordList(['data']),\n",
              " WordList(['science']),\n",
              " WordList(['It']),\n",
              " WordList(['helps']),\n",
              " WordList(['community']),\n",
              " WordList(['through']),\n",
              " WordList(['blogs']),\n",
              " WordList(['Youtube']),\n",
              " WordList(['GLA']),\n",
              " WordList(['etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.ngrams(n = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Viqxai7lsrFd",
        "outputId": "861ad52e-d0ff-448f-bbe2-0b84aa7e357a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great', 'Learning']),\n",
              " WordList(['Learning', 'is']),\n",
              " WordList(['is', 'a']),\n",
              " WordList(['a', 'great']),\n",
              " WordList(['great', 'platform']),\n",
              " WordList(['platform', 'to']),\n",
              " WordList(['to', 'learn']),\n",
              " WordList(['learn', 'data']),\n",
              " WordList(['data', 'science']),\n",
              " WordList(['science', 'It']),\n",
              " WordList(['It', 'helps']),\n",
              " WordList(['helps', 'community']),\n",
              " WordList(['community', 'through']),\n",
              " WordList(['through', 'blogs']),\n",
              " WordList(['blogs', 'Youtube']),\n",
              " WordList(['Youtube', 'GLA']),\n",
              " WordList(['GLA', 'etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.ngrams(n = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-2Rh_F8srkj",
        "outputId": "b1126238-dad6-440c-d25b-b9171eed0a64"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great', 'Learning', 'is']),\n",
              " WordList(['Learning', 'is', 'a']),\n",
              " WordList(['is', 'a', 'great']),\n",
              " WordList(['a', 'great', 'platform']),\n",
              " WordList(['great', 'platform', 'to']),\n",
              " WordList(['platform', 'to', 'learn']),\n",
              " WordList(['to', 'learn', 'data']),\n",
              " WordList(['learn', 'data', 'science']),\n",
              " WordList(['data', 'science', 'It']),\n",
              " WordList(['science', 'It', 'helps']),\n",
              " WordList(['It', 'helps', 'community']),\n",
              " WordList(['helps', 'community', 'through']),\n",
              " WordList(['community', 'through', 'blogs']),\n",
              " WordList(['through', 'blogs', 'Youtube']),\n",
              " WordList(['blogs', 'Youtube', 'GLA']),\n",
              " WordList(['Youtube', 'GLA', 'etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.ngrams(n = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhqRm5uosrsn",
        "outputId": "f8648ede-f7d4-465c-c4e5-0ced90b49765"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Great', 'Learning', 'is', 'a']),\n",
              " WordList(['Learning', 'is', 'a', 'great']),\n",
              " WordList(['is', 'a', 'great', 'platform']),\n",
              " WordList(['a', 'great', 'platform', 'to']),\n",
              " WordList(['great', 'platform', 'to', 'learn']),\n",
              " WordList(['platform', 'to', 'learn', 'data']),\n",
              " WordList(['to', 'learn', 'data', 'science']),\n",
              " WordList(['learn', 'data', 'science', 'It']),\n",
              " WordList(['data', 'science', 'It', 'helps']),\n",
              " WordList(['science', 'It', 'helps', 'community']),\n",
              " WordList(['It', 'helps', 'community', 'through']),\n",
              " WordList(['helps', 'community', 'through', 'blogs']),\n",
              " WordList(['community', 'through', 'blogs', 'Youtube']),\n",
              " WordList(['through', 'blogs', 'Youtube', 'GLA']),\n",
              " WordList(['blogs', 'Youtube', 'GLA', 'etc'])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}